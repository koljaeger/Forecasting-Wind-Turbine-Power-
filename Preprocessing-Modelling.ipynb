{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGd3PTAiI_v0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from keras.layers import LSTM, Dense, Dropout, GRU\n",
        "from keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQWppMm7I_v4"
      },
      "outputs": [],
      "source": [
        "#read in data\n",
        "df = pd.read_csv('data/hourly_nm.csv',index_col='Date/Time')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xm8qobQHI_v5"
      },
      "outputs": [],
      "source": [
        "print(df.info())\n",
        "print()\n",
        "print(df.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-a_LLjsTI_v6"
      },
      "outputs": [],
      "source": [
        "#split data into training and testing, testing data will be one month\n",
        "start_test = '2018-11-31'\n",
        "\n",
        "train, test = df.loc[:start_test], df.loc[start_test:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOky-SN3I_v7"
      },
      "outputs": [],
      "source": [
        "train.tail(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLpKxi65I_v8"
      },
      "outputs": [],
      "source": [
        "test.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXZnM5EqI_v-"
      },
      "outputs": [],
      "source": [
        "print(len(train))\n",
        "print(len(test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQGD_5h3I_v-"
      },
      "outputs": [],
      "source": [
        "# scale the data using MinMax Scaler from -1 to 1 as LSTM & GRU has a default tanh activation function\n",
        "SCALER = MinMaxScaler(feature_range=(-1,1))\n",
        "\n",
        "scaler = SCALER.fit(train.to_numpy())\n",
        "\n",
        "train_scaled = scaler.transform(train.to_numpy())\n",
        "test_scaled = scaler.transform(test.to_numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Puc4daWoI_v_"
      },
      "outputs": [],
      "source": [
        "# create a function to split the datasets into two week windows\n",
        "timestep = 24*7*2 # 24hours,7days,2weeks\n",
        "\n",
        "def create_dataset(dataset, timestep=timestep):\n",
        "    \"\"\"\n",
        "    Function which creates two week chunks of x_train data, and a single\n",
        "    value for y_train.\n",
        "    \"\"\"\n",
        "    X, y = [], []\n",
        "    for i in range(len(dataset)):\n",
        "        target_value = i + timestep\n",
        "        if target_value == len(dataset):\n",
        "            break\n",
        "        feature_chunk, target = dataset[i:target_value, 1:], dataset[target_value, 0]\n",
        "        X.append(feature_chunk)\n",
        "        y.append(target)\n",
        "\n",
        "    return np.array(X), np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-yBJ8sCI_v_"
      },
      "outputs": [],
      "source": [
        "#create x_train, y_train, X_test,y_test\n",
        "X_train, y_train = create_dataset(train_scaled)\n",
        "X_test, y_test = create_dataset(test_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBvPR0qaI_wA"
      },
      "outputs": [],
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4eyoHP0I_wB"
      },
      "outputs": [],
      "source": [
        "# use sample of th data to train network to have a rough understanding of hyperparameters\n",
        "samp_len = int(len(X_train)*0.5)\n",
        "\n",
        "X_sample_train, y_sample_train = X_train[:samp_len], y_train[:samp_len]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVQ0FcXHI_wB"
      },
      "outputs": [],
      "source": [
        "print(X_sample_train.shape)\n",
        "print(y_sample_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewGKAiX_I_wB"
      },
      "outputs": [],
      "source": [
        "# create X_train, y_train, X_test, y_test datasets\n",
        "# create a function to build a stacked GRU model\n",
        "# input needs to be [samples, timesteps, features]\n",
        "def create_model(X_train, y_train):\n",
        "    units = 32\n",
        "    dropout = 0.05\n",
        "    epochs = 35\n",
        "    batch_size = 14\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=0.0005)\n",
        "    early_stopping = EarlyStopping(patience=7, monitor='loss')\n",
        "\n",
        "    model = keras.Sequential()\n",
        "\n",
        "    #model.add(LSTM(units=units, dropout=dropout, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "\n",
        "    #model.add(LSTM(units=units, dropout=dropout))\n",
        "\n",
        "    model.add(GRU(units=units))\n",
        "\n",
        "    model.add(Dense(units=1))\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "    history = model.fit(X_train, y_train, validation_split=0.3, shuffle=False,\n",
        "              epochs=epochs, batch_size=batch_size, verbose=1, callbacks=[early_stopping])\n",
        "\n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBXLvFQlI_wC"
      },
      "outputs": [],
      "source": [
        "# function to predict a single value\n",
        "def single_prediction(model, history, timestep=timestep):\n",
        "\n",
        "        history = np.array(history)\n",
        "        history = history.reshape(history.shape[0]*history.shape[1], history.shape[2])\n",
        "\n",
        "        input_value = history[-timestep:]\n",
        "        input_value = input_value.reshape(1, input_value.shape[0], input_value.shape[1])\n",
        "\n",
        "        yhat = model.predict(input_value, verbose=0)\n",
        "        return yhat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "foLOWvbPI_wC"
      },
      "outputs": [],
      "source": [
        "# function which takes first test chunk, makes a prediction, add the test chunk back into training data\n",
        "#to make next prediction\n",
        "\n",
        "def walk_forward_prediction(X_train, y_train, X_test, timestep):\n",
        "\n",
        "    MODEL, history = create_model(X_train=X_train, y_train=y_train)\n",
        "    hist_train = [i for i in X_train]\n",
        "    predictions = []\n",
        "\n",
        "    for i in range(len(X_test)):\n",
        "        test = X_test[i]\n",
        "        yhat = single_prediction(model=MODEL, history=hist_train, timestep=timestep)\n",
        "        predictions.append(yhat)\n",
        "        hist_train.append(test)\n",
        "\n",
        "    return predictions, history, MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_W07VraBI_wC"
      },
      "outputs": [],
      "source": [
        "def prior_inverse(features, targets):\n",
        "    '''\n",
        "    Append prediction value to test dataset and return a test shape format.\n",
        "    '''\n",
        "    dataset = []\n",
        "\n",
        "    for i in range(features.shape[0]):\n",
        "        last_row, target = features[i][0], targets[i]\n",
        "        appended = np.append(last_row, target)\n",
        "        dataset.append(appended)\n",
        "\n",
        "    return np.array(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "QOAWxRIKI_wD"
      },
      "outputs": [],
      "source": [
        "#run experiemnt returning the real, predicted values\n",
        "def experiment(X_train, y_train, X_test, timestep):\n",
        "\n",
        "    pred_seq, history, MODEL = walk_forward_prediction(X_train, y_train, X_test, timestep)\n",
        "\n",
        "    pred_seq = np.array(pred_seq).reshape(-1)\n",
        "\n",
        "    pred = prior_inverse(X_test, pred_seq)\n",
        "    real = prior_inverse(X_test, y_test)\n",
        "\n",
        "    inv_pred = scaler.inverse_transform(pred)\n",
        "    inv_real = scaler.inverse_transform(real)\n",
        "\n",
        "    power_pred = inv_pred[:,-1]\n",
        "    power_real = inv_real[:,-1]\n",
        "\n",
        "    return power_real, power_pred, history, MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "UF28GZy8I_wD"
      },
      "outputs": [],
      "source": [
        "power_real, power_pred, history, MODEL = experiment(X_train, y_train, X_test, timestep)\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSNsCegqI_wE"
      },
      "outputs": [],
      "source": [
        "#plot validation and training convergence graph\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(loss, label='train')\n",
        "plt.plot(val_loss, label='validation')\n",
        "plt.legend()\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('MSE')\n",
        "plt.title('GRU Training Validation Loss')\n",
        "plt.tight_layout()\n",
        "plt.savefig('figures/GRU_train_val_plot.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nd7WUKh3I_wF"
      },
      "outputs": [],
      "source": [
        "x_plot = test[timestep:].index\n",
        "pred_df = pd.DataFrame({'Date':x_plot, 'Prediction': power_pred, 'True': power_real})\n",
        "pred_df.set_index('Date', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJN3CuSPI_wF"
      },
      "outputs": [],
      "source": [
        "pred_df2 = pred_df['2018-12-15 01:00:00\t':'2018-12-29 02:00:00 ']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WooL7izkI_wF"
      },
      "outputs": [],
      "source": [
        "#plot predictions\n",
        "pred_df2.plot(figsize=(10,5))\n",
        "plt.title('Predicted Power vs Actual Power with GRU an Model.')\n",
        "plt.ylabel('Power(KWh)')\n",
        "plt.tight_layout()\n",
        "plt.savefig('figures/GRU_prediction.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPW7iJRaI_wG"
      },
      "outputs": [],
      "source": [
        "#compute metrics\n",
        "rmse = np.sqrt(mean_squared_error(pred_df2['True'], pred_df2['Prediction']))\n",
        "mae = mean_absolute_error(pred_df2['True'], pred_df2['Prediction'])\n",
        "r2 = r2_score(pred_df2['True'], pred_df2['Prediction'])\n",
        "print('RMSE: {}\\nMAE: {}\\nR2: {}'.format(round(rmse,2),round(mae,2), round(r2,2)))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}